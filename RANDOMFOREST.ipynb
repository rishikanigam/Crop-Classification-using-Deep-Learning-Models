{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2967a9-7cc3-4da0-8fc7-218ca058a2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "Updated_Crop_class_Garlic       0.57      0.65      0.61        43\n",
      "Updated_Crop_class_Onion1       0.36      0.50      0.42        34\n",
      "Updated_Crop_class_Wheat1       0.75      0.66      0.70        50\n",
      "Updated_Crop_class_Wheat2       0.59      0.40      0.48        40\n",
      "\n",
      "                 accuracy                           0.56       167\n",
      "                macro avg       0.57      0.55      0.55       167\n",
      "             weighted avg       0.59      0.56      0.57       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "# Function to normalize bands\n",
    "def normalize_band(band):\n",
    "    return band / np.max(band)\n",
    "\n",
    "# Function to calculate NDVI\n",
    "def calculate_ndvi(red_band, nir_band):\n",
    "    ndvi = (nir_band - red_band) / (nir_band + red_band)\n",
    "    return ndvi\n",
    "\n",
    "# Paths to Sentinel-1 and Sentinel-2 directories (replace with your paths)\n",
    "sentinel1_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_1\"\n",
    "sentinel2_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_2\"\n",
    "shapefile_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\crop_data_shapefile\\merged_crop_data.shp\"\n",
    "\n",
    "# List all Sentinel-1 and Sentinel-2 files\n",
    "sentinel1_files = [os.path.join(sentinel1_dir, f) for f in os.listdir(sentinel1_dir) if f.endswith('.tif')]\n",
    "sentinel2_files = [os.path.join(sentinel2_dir, f) for f in os.listdir(sentinel2_dir) if f.endswith('.tif')]\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Extract features from each polygon in the shapefile\n",
    "patch_size = 64  # Increased the size of patches to extract\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for sentinel1_path, sentinel2_path in zip(sentinel1_files, sentinel2_files):\n",
    "    # Open and read Sentinel-1 data (assuming multi-band)\n",
    "    with rasterio.open(sentinel1_path) as src:\n",
    "        sentinel1_data = src.read()  # Read all bands\n",
    "        sentinel1_meta = src.meta\n",
    "\n",
    "    # Open and read Sentinel-2 data (all bands)\n",
    "    with rasterio.open(sentinel2_path) as src:\n",
    "        sentinel2_data = src.read()  # Read all bands\n",
    "        sentinel2_meta = src.meta\n",
    "\n",
    "    # Ensure the coordinate reference systems match\n",
    "    gdf = gdf.to_crs(sentinel1_meta['crs'])\n",
    "\n",
    "    # Extract individual bands from Sentinel-2 data\n",
    "    sentinel2_red = sentinel2_data[3].astype(float)  # Red band (Band 4)\n",
    "    sentinel2_nir = sentinel2_data[7].astype(float)  # Near Infrared band (Band 8)\n",
    "\n",
    "    # Normalize Sentinel-2 bands\n",
    "    sentinel2_red_norm = normalize_band(sentinel2_red)\n",
    "    sentinel2_nir_norm = normalize_band(sentinel2_nir)\n",
    "\n",
    "    # Calculate NDVI using Sentinel-2 bands\n",
    "    ndvi = calculate_ndvi(sentinel2_red_norm, sentinel2_nir_norm)\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geom = row['geometry']\n",
    "        label = row['layer']  # Replace with the actual column name for crop types\n",
    "\n",
    "        # Create a mask for the polygon\n",
    "        mask = geometry_mask([geom], transform=sentinel1_meta['transform'], invert=True, out_shape=(sentinel1_meta['height'], sentinel1_meta['width']))\n",
    "\n",
    "        # Extract patches of Sentinel-1 and Sentinel-2 data\n",
    "        for i in range(0, sentinel1_meta['height'], patch_size):\n",
    "            for j in range(0, sentinel1_meta['width'], patch_size):\n",
    "                if mask[i:i+patch_size, j:j+patch_size].sum() > 0:  # Ensure there is some data in the patch\n",
    "                    sentinel1_patch = sentinel1_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                    sentinel2_patch = np.array([sentinel2_red[i:i+patch_size, j:j+patch_size], sentinel2_nir[i:i+patch_size, j:j+patch_size]])\n",
    "                    ndvi_patch = ndvi[i:i+patch_size, j:j+patch_size]\n",
    "\n",
    "                    if sentinel1_patch.shape[1] == patch_size and sentinel1_patch.shape[2] == patch_size:\n",
    "                        combined_patch = np.concatenate((sentinel1_patch, sentinel2_patch, np.expand_dims(ndvi_patch, axis=0)), axis=0)\n",
    "                        features.append(combined_patch)\n",
    "                        labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i, :, :] = scaler.fit_transform(features[:, i, :, :].reshape(-1, features[:, i, :, :].shape[-1])).reshape(features[:, i, :, :].shape)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "original_shape = features.shape\n",
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_flat, labels_encoded)\n",
    "features_resampled = features_resampled.reshape(-1, original_shape[1], original_shape[2], original_shape[3])\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten X_train and X_test for RandomForestClassifier\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_flatten, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test_flatten)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff646e6-4ca5-4d7c-8124-987eee7fdf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "Updated_Crop_class_Garlic       0.57      0.65      0.61        43\n",
      "Updated_Crop_class_Onion1       0.36      0.50      0.42        34\n",
      "Updated_Crop_class_Wheat1       0.75      0.66      0.70        50\n",
      "Updated_Crop_class_Wheat2       0.59      0.40      0.48        40\n",
      "\n",
      "                 accuracy                           0.56       167\n",
      "                macro avg       0.57      0.55      0.55       167\n",
      "             weighted avg       0.59      0.56      0.57       167\n",
      "\n",
      "Model saved to C:\\Users\\rishi\\OneDrive\\Desktop\\random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "import joblib\n",
    "\n",
    "# Function to normalize bands\n",
    "def normalize_band(band):\n",
    "    return band / np.max(band)\n",
    "\n",
    "# Function to calculate NDVI\n",
    "def calculate_ndvi(red_band, nir_band):\n",
    "    ndvi = (nir_band - red_band) / (nir_band + red_band)\n",
    "    return ndvi\n",
    "\n",
    "# Paths to Sentinel-1 and Sentinel-2 directories (replace with your paths)\n",
    "sentinel1_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_1\"\n",
    "sentinel2_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_2\"\n",
    "shapefile_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\crop_data_shapefile\\merged_crop_data.shp\"\n",
    "\n",
    "# List all Sentinel-1 and Sentinel-2 files\n",
    "sentinel1_files = [os.path.join(sentinel1_dir, f) for f in os.listdir(sentinel1_dir) if f.endswith('.tif')]\n",
    "sentinel2_files = [os.path.join(sentinel2_dir, f) for f in os.listdir(sentinel2_dir) if f.endswith('.tif')]\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Extract features from each polygon in the shapefile\n",
    "patch_size = 64  # Increased the size of patches to extract\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for sentinel1_path, sentinel2_path in zip(sentinel1_files, sentinel2_files):\n",
    "    # Open and read Sentinel-1 data (assuming multi-band)\n",
    "    with rasterio.open(sentinel1_path) as src:\n",
    "        sentinel1_data = src.read()  # Read all bands\n",
    "        sentinel1_meta = src.meta\n",
    "\n",
    "    # Open and read Sentinel-2 data (all bands)\n",
    "    with rasterio.open(sentinel2_path) as src:\n",
    "        sentinel2_data = src.read()  # Read all bands\n",
    "        sentinel2_meta = src.meta\n",
    "\n",
    "    # Ensure the coordinate reference systems match\n",
    "    gdf = gdf.to_crs(sentinel1_meta['crs'])\n",
    "\n",
    "    # Extract individual bands from Sentinel-2 data\n",
    "    sentinel2_red = sentinel2_data[3].astype(float)  # Red band (Band 4)\n",
    "    sentinel2_nir = sentinel2_data[7].astype(float)  # Near Infrared band (Band 8)\n",
    "\n",
    "    # Normalize Sentinel-2 bands\n",
    "    sentinel2_red_norm = normalize_band(sentinel2_red)\n",
    "    sentinel2_nir_norm = normalize_band(sentinel2_nir)\n",
    "\n",
    "    # Calculate NDVI using Sentinel-2 bands\n",
    "    ndvi = calculate_ndvi(sentinel2_red_norm, sentinel2_nir_norm)\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geom = row['geometry']\n",
    "        label = row['layer']  # Replace with the actual column name for crop types\n",
    "\n",
    "        # Create a mask for the polygon\n",
    "        mask = geometry_mask([geom], transform=sentinel1_meta['transform'], invert=True, out_shape=(sentinel1_meta['height'], sentinel1_meta['width']))\n",
    "\n",
    "        # Extract patches of Sentinel-1 and Sentinel-2 data\n",
    "        for i in range(0, sentinel1_meta['height'], patch_size):\n",
    "            for j in range(0, sentinel1_meta['width'], patch_size):\n",
    "                if mask[i:i+patch_size, j:j+patch_size].sum() > 0:  # Ensure there is some data in the patch\n",
    "                    sentinel1_patch = sentinel1_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                    sentinel2_patch = np.array([sentinel2_red[i:i+patch_size, j:j+patch_size], sentinel2_nir[i:i+patch_size, j:j+patch_size]])\n",
    "                    ndvi_patch = ndvi[i:i+patch_size, j:j+patch_size]\n",
    "\n",
    "                    if sentinel1_patch.shape[1] == patch_size and sentinel1_patch.shape[2] == patch_size:\n",
    "                        combined_patch = np.concatenate((sentinel1_patch, sentinel2_patch, np.expand_dims(ndvi_patch, axis=0)), axis=0)\n",
    "                        features.append(combined_patch)\n",
    "                        labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i, :, :] = scaler.fit_transform(features[:, i, :, :].reshape(-1, features[:, i, :, :].shape[-1])).reshape(features[:, i, :, :].shape)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "original_shape = features.shape\n",
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_flat, labels_encoded)\n",
    "features_resampled = features_resampled.reshape(-1, original_shape[1], original_shape[2], original_shape[3])\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten X_train and X_test for RandomForestClassifier\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_flatten, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test_flatten)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Save the trained model to the local device\n",
    "model_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\random_forest_model.joblib\"\n",
    "joblib.dump(rf_classifier, model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598f22f-9c16-4ddc-9d54-ae66a8c6fe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
