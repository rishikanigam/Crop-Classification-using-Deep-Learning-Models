{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b024d9b9-ad74-4563-98b0-cbd1f90c7a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 342ms/step - accuracy: 0.3305 - loss: 1.3721 - val_accuracy: 0.4808 - val_loss: 1.2509\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.5365 - loss: 1.2061 - val_accuracy: 0.4615 - val_loss: 1.2059\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5116 - loss: 1.1334 - val_accuracy: 0.4808 - val_loss: 1.2265\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.5519 - loss: 1.0569 - val_accuracy: 0.4808 - val_loss: 1.2225\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.5547 - loss: 1.0101 - val_accuracy: 0.5000 - val_loss: 1.2118\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.6232 - loss: 0.9360 - val_accuracy: 0.4615 - val_loss: 1.2746\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6072 - loss: 0.9294 - val_accuracy: 0.5000 - val_loss: 1.2842\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.6171 - loss: 0.8910 - val_accuracy: 0.5577 - val_loss: 1.2680\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.5560 - loss: 0.9590 - val_accuracy: 0.5192 - val_loss: 1.2485\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.5920 - loss: 0.9223 - val_accuracy: 0.5192 - val_loss: 1.2359\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.5459 - loss: 1.0053 - val_accuracy: 0.5192 - val_loss: 1.2697\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.5779 - loss: 0.9213 - val_accuracy: 0.5385 - val_loss: 1.2869\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.6246 - loss: 0.8654 - val_accuracy: 0.5192 - val_loss: 1.2940\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.6013 - loss: 0.8551 - val_accuracy: 0.5000 - val_loss: 1.3008\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.6159 - loss: 0.9119 - val_accuracy: 0.5000 - val_loss: 1.2984\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.6027 - loss: 0.8709 - val_accuracy: 0.5192 - val_loss: 1.2579\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.6424 - loss: 0.8320 - val_accuracy: 0.5192 - val_loss: 1.2567\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.5365 - loss: 0.9156 - val_accuracy: 0.4423 - val_loss: 1.3504\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.6197 - loss: 0.8426 - val_accuracy: 0.4615 - val_loss: 1.3546\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.6218 - loss: 0.8553 - val_accuracy: 0.5192 - val_loss: 1.3192\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 927ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Crop_class_Garlic       0.59      0.53      0.56        19\n",
      "Crop_class_Onion1       0.50      0.18      0.27        11\n",
      "Crop_class_Wheat1       0.52      0.79      0.63        14\n",
      "Crop_class_Wheat2       0.40      0.50      0.44         8\n",
      "\n",
      "         accuracy                           0.52        52\n",
      "        macro avg       0.50      0.50      0.47        52\n",
      "     weighted avg       0.52      0.52      0.50        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to normalize bands\n",
    "def normalize_band(band):\n",
    "    return band / np.max(band)\n",
    "\n",
    "# Function to calculate NDVI\n",
    "def calculate_ndvi(red_band, nir_band):\n",
    "    ndvi = (nir_band - red_band) / (nir_band + red_band)\n",
    "    return ndvi\n",
    "\n",
    "# Function to load all valid TIFF files from a folder\n",
    "def load_tiff_files(folder_path):\n",
    "    tiff_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.tif') or file.endswith('.tiff'):\n",
    "            tiff_files.append(os.path.join(folder_path, file))\n",
    "    return tiff_files\n",
    "\n",
    "# Function to read Sentinel-1 data\n",
    "def read_sentinel1_data(folder_path):\n",
    "    sentinel1_files = load_tiff_files(folder_path)\n",
    "    sentinel1_data = []\n",
    "    sentinel1_meta = None\n",
    "    for file in sentinel1_files:\n",
    "        try:\n",
    "            with rasterio.open(file) as src:\n",
    "                sentinel1_data.append(src.read())  # Read all bands\n",
    "                if sentinel1_meta is None:\n",
    "                    sentinel1_meta = src.meta\n",
    "        except rasterio.errors.RasterioIOError as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    sentinel1_data = np.concatenate(sentinel1_data, axis=0)\n",
    "    return sentinel1_data, sentinel1_meta\n",
    "\n",
    "# Function to read Sentinel-2 data\n",
    "def read_sentinel2_data(folder_path):\n",
    "    sentinel2_files = load_tiff_files(folder_path)\n",
    "    sentinel2_data = []\n",
    "    sentinel2_meta = None\n",
    "    for file in sentinel2_files:\n",
    "        try:\n",
    "            with rasterio.open(file) as src:\n",
    "                sentinel2_data.append(src.read())\n",
    "                if sentinel2_meta is None:\n",
    "                    sentinel2_meta = src.meta\n",
    "        except rasterio.errors.RasterioIOError as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    return sentinel2_data, sentinel2_meta\n",
    "\n",
    "# Paths to Sentinel data folders and shapefile\n",
    "sentinel1_folder_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_1\"\n",
    "sentinel2_folder_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_2\"\n",
    "shapefile_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\merged for training\\crop_data_merged.shp\"\n",
    "\n",
    "# Read and process Sentinel data\n",
    "sentinel1_data, sentinel1_meta = read_sentinel1_data(sentinel1_folder_path)\n",
    "sentinel2_data, sentinel2_meta = read_sentinel2_data(sentinel2_folder_path)\n",
    "\n",
    "# Extract individual bands from Sentinel-2 data and combine them\n",
    "sentinel2_red = []\n",
    "sentinel2_nir = []\n",
    "for data in sentinel2_data:\n",
    "    sentinel2_red.append(data[3].astype(float))  # Red band (Band 4)\n",
    "    sentinel2_nir.append(data[7].astype(float))  # Near Infrared band (Band 8))\n",
    "sentinel2_red = np.concatenate(sentinel2_red, axis=0)\n",
    "sentinel2_nir = np.concatenate(sentinel2_nir, axis=0)\n",
    "\n",
    "# Normalize Sentinel-2 bands\n",
    "sentinel2_red_norm = normalize_band(sentinel2_red)\n",
    "sentinel2_nir_norm = normalize_band(sentinel2_nir)\n",
    "\n",
    "# Calculate NDVI using Sentinel-2 bands\n",
    "ndvi = calculate_ndvi(sentinel2_red_norm, sentinel2_nir_norm)\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Ensure the coordinate reference systems match\n",
    "gdf = gdf.to_crs(sentinel1_meta['crs'])\n",
    "\n",
    "# Extract features from each polygon in the shapefile\n",
    "patch_size = 64  # Size of patches to extract\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in gdf.iterrows():\n",
    "    geom = row['geometry']\n",
    "    label = row['layer']  \n",
    "    \n",
    "    # Create a mask for the polygon\n",
    "    mask = geometry_mask([geom], transform=sentinel1_meta['transform'], invert=True, out_shape=(sentinel1_meta['height'], sentinel1_meta['width']))\n",
    "    \n",
    "    # Extract patches of Sentinel-1 and Sentinel-2 data\n",
    "    for i in range(0, sentinel1_meta['height'], patch_size):\n",
    "        for j in range(0, sentinel1_meta['width'], patch_size):\n",
    "            if mask[i:i+patch_size, j:j+patch_size].sum() > 0:  # Ensure there is some data in the patch\n",
    "                sentinel1_patch = sentinel1_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                sentinel2_patch = np.array([sentinel2_red[i:i+patch_size, j:j+patch_size], sentinel2_nir[i:i+patch_size, j:j+patch_size]])\n",
    "                ndvi_patch = ndvi[i:i+patch_size, j:j+patch_size]\n",
    "                \n",
    "                if sentinel1_patch.shape[1] == patch_size and sentinel1_patch.shape[2] == patch_size:\n",
    "                    combined_patch = np.concatenate((sentinel1_patch, sentinel2_patch, np.expand_dims(ndvi_patch, axis=0)), axis=0)\n",
    "                    features.append(combined_patch)\n",
    "                    labels.append(label)\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i, :, :] = scaler.fit_transform(features[:, i, :, :].reshape(-1, features[:, i, :, :].shape[-1])).reshape(features[:, i, :, :].shape)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "original_shape = features.shape\n",
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_flat, labels_encoded)\n",
    "features_resampled = features_resampled.reshape(-1, original_shape[1], original_shape[2], original_shape[3])\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels_resampled = to_categorical(labels_resampled)\n",
    "\n",
    "# Reshape features for RNN input (batch_size, timesteps, input_dim)\n",
    "features_resampled_rnn = features_resampled.reshape(features_resampled.shape[0], patch_size, -1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_resampled_rnn, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(labels_resampled.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5afae-996e-492a-b56b-dd306620bbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
