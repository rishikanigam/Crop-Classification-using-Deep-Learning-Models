{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb15a64-1bcb-4ebf-a8ab-5e6ad4ebf088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.3132 - loss: 1.6203 - val_accuracy: 0.5808 - val_loss: 1.1207\n",
      "Epoch 2/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4973 - loss: 1.1850 - val_accuracy: 0.5329 - val_loss: 1.0686\n",
      "Epoch 3/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5179 - loss: 1.0815 - val_accuracy: 0.5389 - val_loss: 1.0417\n",
      "Epoch 4/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5257 - loss: 1.0392 - val_accuracy: 0.6108 - val_loss: 1.0055\n",
      "Epoch 5/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5636 - loss: 1.0047 - val_accuracy: 0.5090 - val_loss: 1.0613\n",
      "Epoch 6/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4979 - loss: 1.0441 - val_accuracy: 0.5629 - val_loss: 1.0066\n",
      "Epoch 7/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5419 - loss: 1.0092 - val_accuracy: 0.5629 - val_loss: 1.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5845 - loss: 0.9599 - val_accuracy: 0.5329 - val_loss: 1.0286\n",
      "Epoch 9/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5867 - loss: 0.9423 - val_accuracy: 0.5629 - val_loss: 1.0425\n",
      "Epoch 10/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5791 - loss: 0.9644 - val_accuracy: 0.5269 - val_loss: 1.0456\n",
      "Epoch 11/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5739 - loss: 0.9510 - val_accuracy: 0.5629 - val_loss: 1.0300\n",
      "Epoch 12/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5780 - loss: 0.9826 - val_accuracy: 0.5749 - val_loss: 1.0125\n",
      "Epoch 13/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5382 - loss: 0.9830 - val_accuracy: 0.5569 - val_loss: 1.0290\n",
      "Epoch 14/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5421 - loss: 1.0077 - val_accuracy: 0.5749 - val_loss: 1.0258\n",
      "Epoch 15/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5581 - loss: 0.9209 - val_accuracy: 0.5569 - val_loss: 1.0086\n",
      "Epoch 16/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5562 - loss: 0.9863 - val_accuracy: 0.5389 - val_loss: 1.0560\n",
      "Epoch 17/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5657 - loss: 0.9501 - val_accuracy: 0.5569 - val_loss: 1.0296\n",
      "Epoch 18/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5885 - loss: 0.9276 - val_accuracy: 0.5509 - val_loss: 1.0392\n",
      "Epoch 19/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6128 - loss: 0.9402 - val_accuracy: 0.5150 - val_loss: 1.0500\n",
      "Epoch 20/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5615 - loss: 0.9456 - val_accuracy: 0.5329 - val_loss: 1.0827\n",
      "Epoch 21/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5513 - loss: 0.9626 - val_accuracy: 0.5988 - val_loss: 1.0317\n",
      "Epoch 22/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5969 - loss: 0.9276 - val_accuracy: 0.5329 - val_loss: 1.0550\n",
      "Epoch 23/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5816 - loss: 0.9337 - val_accuracy: 0.5868 - val_loss: 1.0577\n",
      "Epoch 24/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6125 - loss: 0.8633 - val_accuracy: 0.5868 - val_loss: 1.0493\n",
      "Epoch 25/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6235 - loss: 0.8816 - val_accuracy: 0.5629 - val_loss: 1.0623\n",
      "Epoch 26/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5424 - loss: 0.9304 - val_accuracy: 0.5449 - val_loss: 1.0522\n",
      "Epoch 27/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5881 - loss: 0.9305 - val_accuracy: 0.5329 - val_loss: 1.0851\n",
      "Epoch 28/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6090 - loss: 0.8983 - val_accuracy: 0.5269 - val_loss: 1.0495\n",
      "Epoch 29/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5919 - loss: 0.9038 - val_accuracy: 0.5988 - val_loss: 1.0651\n",
      "Epoch 30/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5359 - loss: 0.9403 - val_accuracy: 0.6108 - val_loss: 1.0813\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "Updated_Crop_class_Garlic       0.57      0.77      0.65        43\n",
      "Updated_Crop_class_Onion1       0.42      0.41      0.42        34\n",
      "Updated_Crop_class_Wheat1       0.78      0.80      0.79        50\n",
      "Updated_Crop_class_Wheat2       0.60      0.38      0.46        40\n",
      "\n",
      "                 accuracy                           0.61       167\n",
      "                macro avg       0.59      0.59      0.58       167\n",
      "             weighted avg       0.61      0.61      0.60       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to normalize bands\n",
    "def normalize_band(band):\n",
    "    return band / np.max(band)\n",
    "\n",
    "# Function to calculate NDVI\n",
    "def calculate_ndvi(red_band, nir_band):\n",
    "    ndvi = (nir_band - red_band) / (nir_band + red_band)\n",
    "    return ndvi\n",
    "\n",
    "# Paths to Sentinel-1 and Sentinel-2 directories (replace with your paths)\n",
    "sentinel1_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_1\"\n",
    "sentinel2_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_2\"\n",
    "shapefile_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\crop_data_shapefile\\merged_crop_data.shp\"\n",
    "\n",
    "# List all Sentinel-1 and Sentinel-2 files\n",
    "sentinel1_files = [os.path.join(sentinel1_dir, f) for f in os.listdir(sentinel1_dir) if f.endswith('.tif')]\n",
    "sentinel2_files = [os.path.join(sentinel2_dir, f) for f in os.listdir(sentinel2_dir) if f.endswith('.tif')]\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Extract features from each polygon in the shapefile\n",
    "patch_size = 64  # Increased the size of patches to extract\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for sentinel1_path, sentinel2_path in zip(sentinel1_files, sentinel2_files):\n",
    "    # Open and read Sentinel-1 data (assuming multi-band)\n",
    "    with rasterio.open(sentinel1_path) as src:\n",
    "        sentinel1_data = src.read()  # Read all bands\n",
    "        sentinel1_meta = src.meta\n",
    "\n",
    "    # Open and read Sentinel-2 data (all bands)\n",
    "    with rasterio.open(sentinel2_path) as src:\n",
    "        sentinel2_data = src.read()  # Read all bands\n",
    "        sentinel2_meta = src.meta\n",
    "\n",
    "    # Ensure the coordinate reference systems match\n",
    "    gdf = gdf.to_crs(sentinel1_meta['crs'])\n",
    "\n",
    "    # Extract individual bands from Sentinel-2 data\n",
    "    sentinel2_red = sentinel2_data[3].astype(float)  # Red band (Band 4)\n",
    "    sentinel2_nir = sentinel2_data[7].astype(float)  # Near Infrared band (Band 8)\n",
    "\n",
    "    # Normalize Sentinel-2 bands\n",
    "    sentinel2_red_norm = normalize_band(sentinel2_red)\n",
    "    sentinel2_nir_norm = normalize_band(sentinel2_nir)\n",
    "\n",
    "    # Calculate NDVI using Sentinel-2 bands\n",
    "    ndvi = calculate_ndvi(sentinel2_red_norm, sentinel2_nir_norm)\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geom = row['geometry']\n",
    "        label = row['layer']  # Replace with the actual column name for crop types\n",
    "\n",
    "        # Create a mask for the polygon\n",
    "        mask = geometry_mask([geom], transform=sentinel1_meta['transform'], invert=True, out_shape=(sentinel1_meta['height'], sentinel1_meta['width']))\n",
    "\n",
    "        # Extract patches of Sentinel-1 and Sentinel-2 data\n",
    "        for i in range(0, sentinel1_meta['height'], patch_size):\n",
    "            for j in range(0, sentinel1_meta['width'], patch_size):\n",
    "                if mask[i:i+patch_size, j:j+patch_size].sum() > 0:  # Ensure there is some data in the patch\n",
    "                    sentinel1_patch = sentinel1_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                    sentinel2_patch = np.array([sentinel2_red[i:i+patch_size, j:j+patch_size], sentinel2_nir[i:i+patch_size, j:j+patch_size]])\n",
    "                    ndvi_patch = ndvi[i:i+patch_size, j:j+patch_size]\n",
    "\n",
    "                    if sentinel1_patch.shape[1] == patch_size and sentinel1_patch.shape[2] == patch_size:\n",
    "                        combined_patch = np.concatenate((sentinel1_patch, sentinel2_patch, np.expand_dims(ndvi_patch, axis=0)), axis=0)\n",
    "                        features.append(combined_patch)\n",
    "                        labels.append(label)\n",
    "\n",
    "                # Save the fused patch\n",
    "                        fused_patch_path = os.path.join(output_dir, f'fused_patch_{idx}_{i}_{j}.tif')\n",
    "                        with rasterio.open(\n",
    "                            fused_patch_path, 'w',\n",
    "                            driver='GTiff',\n",
    "                            height=combined_patch.shape[1],\n",
    "                            width=combined_patch.shape[2],\n",
    "                            count=combined_patch.shape[0],\n",
    "                            dtype=combined_patch.dtype,\n",
    "                            crs=sentinel1_meta['crs'],\n",
    "                            transform=sentinel1_meta['transform']\n",
    "                        ) as dst:\n",
    "                            for band in range(combined_patch.shape[0]):\n",
    "                                dst.write(combined_patch[band, :, :], band + 1)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i, :, :] = scaler.fit_transform(features[:, i, :, :].reshape(-1, features[:, i, :, :].shape[-1])).reshape(features[:, i, :, :].shape)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "original_shape = features.shape\n",
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_flat, labels_encoded)\n",
    "features_resampled = features_resampled.reshape(-1, original_shape[1], original_shape[2], original_shape[3])\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels_resampled = to_categorical(labels_resampled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(features_resampled.shape[1], features_resampled.shape[2], features_resampled.shape[3])))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(labels_resampled.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=25, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db033d8-f69d-4863-901d-175e5e7363b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - accuracy: 0.3291 - loss: 1.5857 - val_accuracy: 0.5449 - val_loss: 1.1128\n",
      "Epoch 2/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5006 - loss: 1.1360 - val_accuracy: 0.5210 - val_loss: 1.0730\n",
      "Epoch 3/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5225 - loss: 1.0778 - val_accuracy: 0.5150 - val_loss: 1.0523\n",
      "Epoch 4/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5528 - loss: 1.0590 - val_accuracy: 0.5329 - val_loss: 1.0671\n",
      "Epoch 5/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5134 - loss: 1.0446 - val_accuracy: 0.5389 - val_loss: 1.0264\n",
      "Epoch 6/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5199 - loss: 1.0503 - val_accuracy: 0.5928 - val_loss: 1.0349\n",
      "Epoch 7/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5863 - loss: 1.0032 - val_accuracy: 0.5090 - val_loss: 1.0588\n",
      "Epoch 8/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5867 - loss: 0.9840 - val_accuracy: 0.5389 - val_loss: 1.0576\n",
      "Epoch 9/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5600 - loss: 0.9781 - val_accuracy: 0.6168 - val_loss: 1.0640\n",
      "Epoch 10/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6047 - loss: 0.9273 - val_accuracy: 0.5150 - val_loss: 1.0602\n",
      "Epoch 11/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5377 - loss: 1.0179 - val_accuracy: 0.5749 - val_loss: 1.0380\n",
      "Epoch 12/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5790 - loss: 0.9236 - val_accuracy: 0.5449 - val_loss: 1.0489\n",
      "Epoch 13/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5944 - loss: 0.9585 - val_accuracy: 0.5269 - val_loss: 1.0744\n",
      "Epoch 14/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5272 - loss: 1.0186 - val_accuracy: 0.5689 - val_loss: 1.0833\n",
      "Epoch 15/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5737 - loss: 0.9942 - val_accuracy: 0.5449 - val_loss: 1.0357\n",
      "Epoch 16/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5739 - loss: 0.9450 - val_accuracy: 0.5689 - val_loss: 1.0696\n",
      "Epoch 17/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5809 - loss: 0.9264 - val_accuracy: 0.5689 - val_loss: 1.0535\n",
      "Epoch 18/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6063 - loss: 0.9104 - val_accuracy: 0.5808 - val_loss: 1.0487\n",
      "Epoch 19/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5966 - loss: 0.9115 - val_accuracy: 0.5629 - val_loss: 1.0825\n",
      "Epoch 20/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5340 - loss: 0.9506 - val_accuracy: 0.5569 - val_loss: 1.0478\n",
      "Epoch 21/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5658 - loss: 0.9801 - val_accuracy: 0.5868 - val_loss: 1.0441\n",
      "Epoch 22/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5668 - loss: 0.9652 - val_accuracy: 0.5509 - val_loss: 1.0857\n",
      "Epoch 23/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5979 - loss: 0.9002 - val_accuracy: 0.6108 - val_loss: 1.0379\n",
      "Epoch 24/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6203 - loss: 0.9131 - val_accuracy: 0.5629 - val_loss: 1.0677\n",
      "Epoch 25/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5634 - loss: 0.9390 - val_accuracy: 0.5689 - val_loss: 1.0871\n",
      "Epoch 26/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6064 - loss: 0.8709 - val_accuracy: 0.5749 - val_loss: 1.0882\n",
      "Epoch 27/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5926 - loss: 0.9150 - val_accuracy: 0.5988 - val_loss: 1.0651\n",
      "Epoch 28/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6130 - loss: 0.9106 - val_accuracy: 0.5749 - val_loss: 1.0830\n",
      "Epoch 29/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6353 - loss: 0.8760 - val_accuracy: 0.4790 - val_loss: 1.0916\n",
      "Epoch 30/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5977 - loss: 0.9125 - val_accuracy: 0.5689 - val_loss: 1.1435\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "Updated_Crop_class_Garlic       0.53      0.70      0.60        43\n",
      "Updated_Crop_class_Onion1       0.38      0.44      0.41        34\n",
      "Updated_Crop_class_Wheat1       0.77      0.66      0.71        50\n",
      "Updated_Crop_class_Wheat2       0.61      0.42      0.50        40\n",
      "\n",
      "                 accuracy                           0.57       167\n",
      "                macro avg       0.57      0.56      0.56       167\n",
      "             weighted avg       0.59      0.57      0.57       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to normalize bands\n",
    "def normalize_band(band):\n",
    "    return band / np.max(band)\n",
    "\n",
    "# Function to calculate NDVI\n",
    "def calculate_ndvi(red_band, nir_band):\n",
    "    ndvi = (nir_band - red_band) / (nir_band + red_band)\n",
    "    return ndvi\n",
    "\n",
    "\n",
    "sentinel1_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_1\"\n",
    "sentinel2_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\sentinel_2\"\n",
    "shapefile_path = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\crop_data_shapefile\\merged_crop_data.shp\"\n",
    "output_dir = r\"C:\\Users\\rishi\\OneDrive\\Desktop\\fused data\"  \n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List all Sentinel-1 and Sentinel-2 files\n",
    "sentinel1_files = [os.path.join(sentinel1_dir, f) for f in os.listdir(sentinel1_dir) if f.endswith('.tif')]\n",
    "sentinel2_files = [os.path.join(sentinel2_dir, f) for f in os.listdir(sentinel2_dir) if f.endswith('.tif')]\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Extract features from each polygon in the shapefile\n",
    "patch_size = 64  # Increased the size of patches to extract\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for sentinel1_path, sentinel2_path in zip(sentinel1_files, sentinel2_files):\n",
    "    # Open and read Sentinel-1 data (assuming multi-band)\n",
    "    with rasterio.open(sentinel1_path) as src:\n",
    "        sentinel1_data = src.read()  # Read all bands\n",
    "        sentinel1_meta = src.meta\n",
    "\n",
    "    # Open and read Sentinel-2 data (all bands)\n",
    "    with rasterio.open(sentinel2_path) as src:\n",
    "        sentinel2_data = src.read()  # Read all bands\n",
    "        sentinel2_meta = src.meta\n",
    "\n",
    "    # Ensure the coordinate reference systems match\n",
    "    gdf = gdf.to_crs(sentinel1_meta['crs'])\n",
    "\n",
    "    # Extract individual bands from Sentinel-2 data\n",
    "    sentinel2_red = sentinel2_data[3].astype(float)  # Red band (Band 4)\n",
    "    sentinel2_nir = sentinel2_data[7].astype(float)  # Near Infrared band (Band 8)\n",
    "\n",
    "    # Normalize Sentinel-2 bands\n",
    "    sentinel2_red_norm = normalize_band(sentinel2_red)\n",
    "    sentinel2_nir_norm = normalize_band(sentinel2_nir)\n",
    "\n",
    "    # Calculate NDVI using Sentinel-2 bands\n",
    "    ndvi = calculate_ndvi(sentinel2_red_norm, sentinel2_nir_norm)\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geom = row['geometry']\n",
    "        label = row['layer']  # Replace with the actual column name for crop types\n",
    "\n",
    "        # Create a mask for the polygon\n",
    "        mask = geometry_mask([geom], transform=sentinel1_meta['transform'], invert=True, out_shape=(sentinel1_meta['height'], sentinel1_meta['width']))\n",
    "\n",
    "        # Extract patches of Sentinel-1 and Sentinel-2 data\n",
    "        for i in range(0, sentinel1_meta['height'], patch_size):\n",
    "            for j in range(0, sentinel1_meta['width'], patch_size):\n",
    "                if mask[i:i+patch_size, j:j+patch_size].sum() > 0:  # Ensure there is some data in the patch\n",
    "                    sentinel1_patch = sentinel1_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                    sentinel2_patch = np.array([sentinel2_red[i:i+patch_size, j:j+patch_size], sentinel2_nir[i:i+patch_size, j:j+patch_size]])\n",
    "                    ndvi_patch = ndvi[i:i+patch_size, j:j+patch_size]\n",
    "\n",
    "                    if sentinel1_patch.shape[1] == patch_size and sentinel1_patch.shape[2] == patch_size:\n",
    "                        combined_patch = np.concatenate((sentinel1_patch, sentinel2_patch, np.expand_dims(ndvi_patch, axis=0)), axis=0)\n",
    "                        features.append(combined_patch)\n",
    "                        labels.append(label)\n",
    "\n",
    "                        # Save the fused patch\n",
    "                        fused_patch_path = os.path.join(output_dir, f'fused_patch_{idx}_{i}_{j}.tif')\n",
    "                        with rasterio.open(\n",
    "                            fused_patch_path, 'w',\n",
    "                            driver='GTiff',\n",
    "                            height=combined_patch.shape[1],\n",
    "                            width=combined_patch.shape[2],\n",
    "                            count=combined_patch.shape[0],\n",
    "                            dtype=combined_patch.dtype,\n",
    "                            crs=sentinel1_meta['crs'],\n",
    "                            transform=sentinel1_meta['transform']\n",
    "                        ) as dst:\n",
    "                            for band in range(combined_patch.shape[0]):\n",
    "                                dst.write(combined_patch[band, :, :], band + 1)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i, :, :] = scaler.fit_transform(features[:, i, :, :].reshape(-1, features[:, i, :, :].shape[-1])).reshape(features[:, i, :, :].shape)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "original_shape = features.shape\n",
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_flat, labels_encoded)\n",
    "features_resampled = features_resampled.reshape(-1, original_shape[1], original_shape[2], original_shape[3])\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels_resampled = to_categorical(labels_resampled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(features_resampled.shape[1], features_resampled.shape[2], features_resampled.shape[3])))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(labels_resampled.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=25, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3827529-f5de-403a-879f-0e6c9b96c8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
